{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of input file paths:\n",
    "\n",
    "/home/ana/Documents/2023/ldms-darshan-analysis/ior/eclipse/darshan-ldms-output/csv/8m-4m/17901504-IOR_pscratch_1024_none.csv\n",
    "/home/ana/Documents/2023/ldms-darshan-analysis/ior/eclipse/darshan-ldms-output/csv/8m-4m/17893042-IOR_pscratch_1024_cpu.csv\n",
    "/home/ana/Documents/2023/ldms-darshan-analysis/ior/eclipse/darshan-ldms-output/csv/8m-4m/17895745-IOR_pscratch_1024_memory.csv\n",
    "\n",
    "Log with multiple jobs:\n",
    "/home/ana/Documents/2023/ldms-darshan-analysis/ior/eclipse/darshan-ldms-output/csv/8m-4m/test_all_jobs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "- [ ] Visualizations code in R and python\n",
    "- [ ] Identify app phase:\n",
    "- [ ] Identify longer operations \n",
    "- [ ] Identify long intervals between last read/write and a met operation open/close \n",
    "- [ ] Identify distance between the first rank to finish and others\n",
    "- [ ] Identify long intervals between operations in the same rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, time, glob, argparse, psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt \n",
    "import rpy2.robjects as ro\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "class Job:\n",
    "\n",
    "    def __init__(self, job, ranks, nodes, users, filename, exe):\n",
    "        \n",
    "        self.job = job\n",
    "        self.ranks = ranks\n",
    "        self.nodes = nodes\n",
    "        self.users = users\n",
    "        self.filename = filename\n",
    "        self.exe = exe\n",
    "\n",
    "def app_phase(df, output_file, self):\n",
    "    write_to_file(\"---------------------------------------\")\n",
    "    write_to_file(\"EXECUTION SUMMARY PER APPLICATION PHASE:\")\n",
    "    write_to_file(\"---------------------------------------\")\n",
    "\n",
    "# Calculate and write general statistics in a file\n",
    "def get_statistics(df, output_file, self):\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "\n",
    "        def write_to_file(*args):\n",
    "            print(\" \".join(map(str, args)), file=f, flush=True)\n",
    "\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"JOB CHARACTERISTICS:\")\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"Job ID:\", self.job)\n",
    "        write_to_file(len(self.ranks), \"Rank (s):\", sorted(self.ranks))\n",
    "        write_to_file(len(self.nodes), \"Node (s):\", sorted(self.nodes))\n",
    "        write_to_file(\"User ID:\", self.users)\n",
    "        write_to_file(\"Directory:\", self.exe)\n",
    "        write_to_file(\"Modules collected:\", df['module'].unique())\n",
    "        write_to_file(\"Module data (MOD):\", list(df.type).count('MOD'))\n",
    "        write_to_file(\"Meta data (MET):\", list(df.type).count('MET'))\n",
    "        exec_time = round(df['end'].max() - df['start'].min(), 5)\n",
    "        write_to_file(\"I/O runtime:\", exec_time, \"seconds\")\n",
    "        write_to_file(\"Bandwidth (MiB/second):\", round((df['len'].sum() / exec_time) / (1024 ** 2), 2))\n",
    "\n",
    "        df_rw = df[df['op'].isin([\"read\", \"write\"])]\n",
    "        df_read = df[df['op'] == \"read\"]\n",
    "        df_write = df[df['op'] == \"write\"]\n",
    "\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"I/O OPERATIONS:\")\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "\n",
    "        current_op = None\n",
    "        phase_start = None\n",
    "        total_durations = {'read': 0, 'write': 0, 'open': 0, 'close': 0}\n",
    "\n",
    "        def update_total_duration(op, phase_start, phase_end, length):\n",
    "            if current_op is not None and current_op == op:\n",
    "                total_durations[op] += (phase_end - phase_start)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            if current_op is None or current_op != row['op']:\n",
    "                update_total_duration(current_op, phase_start, row['end'], row['len'])\n",
    "                current_op = row['op']\n",
    "                phase_start = row['start']\n",
    "\n",
    "        # Get the last phase\n",
    "        update_total_duration(current_op, phase_start, row['end'], row['len'])\n",
    "\n",
    "        pivot_df = df.pivot_table(index=None, columns='op', values='len', aggfunc='sum')\n",
    "        for op, duration in total_durations.items():\n",
    "            write_to_file(f'Duration {op}s: {round(duration, 4)} seconds')\n",
    "            if op == \"read\" or op == \"write\":\n",
    "                bytesproc = round((pivot_df[op].max() / (1024 ** 2)) / duration, 4)\n",
    "                write_to_file(\"Bandwidth:\", bytesproc, \"(MiB/second)\")\n",
    "\n",
    "        write_to_file(\"\\nREADS:\", round(df_read['len'].sum() / (1024 ** 2)),  \"(MiB)\")\n",
    "        write_to_file(\"Max size per rank:\", round(df_read.groupby('rank')['len'].agg('sum').max() / (1024 ** 2)), \"MiB\")\n",
    "        write_to_file(\"Min size per rank:\", round(df_read.groupby('rank')['len'].agg('sum').min() / (1024 ** 2)), \"MiB\")\n",
    "        write_to_file(\"Bandwidth (MiB/second):\", round((df_read['len'].sum() / (df_read['end'].max() - df_read['start'].min())) / (1024 ** 2), 2))\n",
    "        \n",
    "        write_to_file(\"\\nWRITES:\", round(df_write['len'].sum() / (1024 ** 2)), \"(MiB)\")\n",
    "        write_to_file(\"Max size per rank:\", round(df_write.groupby('rank')['len'].agg('sum').max() / (1024 ** 2)), \"MiB\")\n",
    "        write_to_file(\"Min size per rank:\", round(df_write.groupby('rank')['len'].agg('sum').min() / (1024 ** 2)), \"MiB\")\n",
    "        write_to_file(\"Bandwidth (MiB/second):\", round((df_write['len'].sum() / (df_write['end'].max() - df_write['start'].min())) / (1024 ** 2),2))\n",
    "\n",
    "        # IMBALANCE METRICS:\n",
    "        # Average = sum time computing / number of ranks\n",
    "        # Imbalance time = time that would be saved if the load was perfectly balanced across resources\n",
    "        # Percent Imbalance = performance that could be gained if load was perfectly balanced\n",
    "        # Imbalance Percentage = percentage of time that resources (excluding the slowest one) are\n",
    "        # not involved in computing\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"LOAD IMBALANCE METRICS:\")\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        # Get difference between execution time and time processing I/O per rank\n",
    "        df_idle = df.groupby('rank')['dur'].sum().reset_index()\n",
    "        df_idle.columns = ['Rank', 'I/O Time']\n",
    "        df_idle['Total time - I/O Time'] = exec_time - df_idle['I/O Time']\n",
    "        df_idle = df_idle.sort_values(by='Total time - I/O Time', ascending=False)\n",
    "\n",
    "        write_to_file(\"Total execution time:\", exec_time)\n",
    "        num_ranks = df_idle['I/O Time'].nunique()\n",
    "        average = df_idle['I/O Time'].sum() / num_ranks\n",
    "        write_to_file(\"- Average:\", round(average), \"seconds\")\n",
    "        it = df_idle['I/O Time'].max() - average\n",
    "        write_to_file(\"- Imbalance Time:\", round(it, 2), \"seconds\")\n",
    "        pi = ((df_idle['I/O Time'].max() / average) - 1) * 100\n",
    "        write_to_file(\"- Percent Imbalance:\", round(pi, 2), \"%\")\n",
    "        ip = (it / df_idle['I/O Time'].max()) * (num_ranks / (num_ranks - 1))\n",
    "        write_to_file(\"- Imbalance Percentage:\", round(ip, 2), \"%\")\n",
    "        std = np.std(df_idle['I/O Time'])\n",
    "        write_to_file(\"- Standard deviation\", round(std, 2))\n",
    "\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"SUMMARY PER RANK: \")\n",
    "        write_to_file(\"---------------------------------------\")\n",
    "        write_to_file(\"Total time without executing I/O operations:\")\n",
    "        df['start'] = pd.to_datetime(df['start'], unit='s').dt.round('S')\n",
    "        df['end'] = pd.to_datetime(df['end'], unit='s').dt.round('S')\n",
    "        write_to_file(df_idle)\n",
    "    \n",
    "# Define jobs characteristics\n",
    "def main(filename): \n",
    "\n",
    "    df = pd.read_csv(filename, engine=\"pyarrow\")\n",
    "\n",
    "    # Get basic info about each Job:\n",
    "    local_df = pd.DataFrame()\n",
    "    for i in df.job_id.unique():\n",
    "        \n",
    "        local_df = df[df['job_id'] == i]\n",
    "        job = Job(i, local_df['rank'].unique(), local_df['ProducerName'].unique(),local_df['uid'].unique(), \n",
    "            local_df['file'].unique(), local_df['exe'].unique())\n",
    "\n",
    "        local_df['start'] = local_df['timestamp'] - local_df['dur']\n",
    "        local_df['end'] = local_df['timestamp']\n",
    "        \n",
    "        # Job characteristics and statistics:  \n",
    "        output_file = filename.replace(\".csv\", \".txt\")\n",
    "        get_statistics(local_df, output_file, job)\n",
    "       \n",
    "        # Job visualizations\n",
    "        # get_visualizations_R(args.input, \"./figures/ior/teste.png\")\n",
    "        # get_visualizations_py(local_df, \"./figures/ior/teste.png\")\n",
    "\n",
    "    # if(system):\n",
    "    #     correlate_system(args.input, args.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35228/3840804214.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df['start'] = local_df['timestamp'] - local_df['dur']\n",
      "/tmp/ipykernel_35228/3840804214.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df['end'] = local_df['timestamp']\n",
      "/tmp/ipykernel_35228/3840804214.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start'] = pd.to_datetime(df['start'], unit='s').dt.round('S')\n",
      "/tmp/ipykernel_35228/3840804214.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['end'] = pd.to_datetime(df['end'], unit='s').dt.round('S')\n",
      "/tmp/ipykernel_35228/3840804214.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df['start'] = local_df['timestamp'] - local_df['dur']\n",
      "/tmp/ipykernel_35228/3840804214.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  local_df['end'] = local_df['timestamp']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution: 14.834666728973389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35228/3840804214.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['start'] = pd.to_datetime(df['start'], unit='s').dt.round('S')\n",
      "/tmp/ipykernel_35228/3840804214.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['end'] = pd.to_datetime(df['end'], unit='s').dt.round('S')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time_exec = time.time()\n",
    "    # filename = input('Insert absolut LDMS-Darshan log path:')\n",
    "    main(\"/home/ana/Documents/2023/ldms-darshan-analysis/ior/eclipse/darshan-ldms-output/csv/8m-4m/test_all_jobs.csv\")   \n",
    "    end_time_exec = time.time()\n",
    "    print(\"Execution:\", end_time_exec - start_time_exec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations in R\n",
    "\n",
    "Load libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "options(crayon.enabled=FALSE)\n",
    "library(dplyr)\n",
    "library(tidyverse) \n",
    "library(arrow)\n",
    "library(lubridate)\n",
    "library(viridis)\n",
    "library(patchwork)\n",
    "library(scales)\n",
    "library(forcats)\n",
    "\n",
    "my_theme <- function() {                                                                                                                       \n",
    "    theme_bw(base_size=10) +                                                                                                                   \n",
    "    theme(panel.background = element_blank(),                                                                                                  \n",
    "        legend.box.margin = margin(0,0,0,0),                                                                                                 \n",
    "        legend.spacing = unit(0, \"pt\"),                                                                                                      \n",
    "        legend.position = \"top\",                                                                                                             \n",
    "        legend.text = element_text(color = \"black\", size = 10),                                                                              \n",
    "        panel.grid.minor = element_blank(),\n",
    "        panel.grid.major = element_blank(),                                                                                                  \n",
    "        strip.text.x = element_text(size = 10),                                                                                              \n",
    "        strip.text.y = element_text(size = 10),                                                                                              \n",
    "        legend.box.spacing = unit(0, \"pt\"))                                                                                                  \n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_temporal <- function(filename, filename_sys, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        mutate(start = timestamp - dur) %>%\n",
    "        mutate(end_datetime = as_datetime(timestamp),\n",
    "            start_datetime = as_datetime(start),) %>%\n",
    "        mutate(start_zero = start - min(start)) %>%\n",
    "        mutate(end_zero = start_zero + dur) %>%\n",
    "        filter(module == \"POSIX\") \n",
    "\n",
    "    df.system <- read_csv(filename_sys) %>%\n",
    "        filter(timestamp >= min(df$start)) %>%\n",
    "        filter(timestamp <= max(df$timestamp))\n",
    "    \n",
    "    df %>% print()\n",
    "    df.system %>% print()\n",
    "\n",
    "    df %>%\n",
    "        ggplot(aes(xmin=start_datetime, xmax=end_datetime, ymin=rank-0.4, ymax=rank+0.4, fill=op)) +\n",
    "        geom_rect() + theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        scale_x_datetime(date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        scale_y_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,4)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p1     \n",
    "\n",
    "    df.system %>%\n",
    "        mutate(t_datetime = as_datetime(timestamp)) %>%\n",
    "        ggplot(aes(x=t_datetime, y=procs_running)) +\n",
    "        geom_line() + geom_point() + my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank(),  axis.title.x=element_blank()) +  \n",
    "        scale_x_datetime(date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p2 \n",
    "\n",
    "    df.system %>%\n",
    "        mutate(t_datetime = as_datetime(timestamp)) %>%\n",
    "        ggplot(aes(x=t_datetime, y=procs_blocked)) +\n",
    "        geom_line() + geom_point() + my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank(),  axis.title.x=element_blank()) +  \n",
    "        scale_x_datetime(date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p3\n",
    "\n",
    "    df.system %>%\n",
    "        mutate(t_datetime = as_datetime(timestamp)) %>%\n",
    "        ggplot(aes(x=t_datetime, y=iowait)) +\n",
    "        geom_line() + geom_point() + my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        scale_x_datetime(date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p4\n",
    "\n",
    "    df.system %>%\n",
    "        mutate(t_datetime = as_datetime(timestamp)) %>%\n",
    "        ggplot(aes(x=t_datetime, y=user+sys)) +\n",
    "        geom_line() + geom_point() + my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank()) + \n",
    "        scale_x_datetime(\"Execution time\", date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p5\n",
    "\n",
    "    df.system %>%\n",
    "        mutate(t_datetime = as_datetime(timestamp)) %>%\n",
    "        ggplot(aes(x=t_datetime, y=softirq)) +\n",
    "        geom_line() + geom_point() + my_theme() + \n",
    "        theme(panel.grid.major.x=element_blank()) + \n",
    "        scale_x_datetime(\"Execution time\", date_breaks = \"10 min\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p6\n",
    "\n",
    "    ggsave(filename=figname, plot = p1/p2/p3/p4/p5/p6, height=8, width=10)                                                                \n",
    "}\n",
    "\n",
    "plot_temporal <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        mutate(start = timestamp - dur) %>%\n",
    "        mutate(end_datetime = as_datetime(timestamp),\n",
    "            start_datetime = as_datetime(start),) %>%\n",
    "        mutate(start_zero = start - min(start)) %>%\n",
    "        mutate(end_zero = start_zero + dur) %>%\n",
    "        filter(module == \"POSIX\")               \n",
    "\n",
    "    df %>%\n",
    "        ggplot(aes(xmin=start_datetime, xmax=end_datetime, ymin=rank-0.4, ymax=rank+0.4, fill=op)) +\n",
    "        geom_rect() + theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        ggtitle(\"Temporal visualization of I/O operations\") +\n",
    "        my_theme() + scale_x_datetime(\"Execution time\", date_breaks = \"10 sec\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        scale_y_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,4)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p      \n",
    "\n",
    "    ggsave(filename=figname, plot = p, height=3, width=10)                                                                   \n",
    "}\n",
    "\n",
    "plot_long_temporal <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        mutate(start = timestamp - dur) %>%\n",
    "        mutate(end_datetime = as_datetime(timestamp),\n",
    "            start_datetime = as_datetime(start),) %>%\n",
    "        mutate(start_zero = start - min(start)) %>%\n",
    "        mutate(end_zero = start_zero + dur) %>%\n",
    "        filter(module == \"POSIX\")               \n",
    "\n",
    "    # Filter only operations that took longer than the median\n",
    "    df %>% group_by(op) %>% \n",
    "        mutate(median_dur = median(dur)) %>%\n",
    "        ungroup() %>%\n",
    "        filter(dur > median_dur) %>%\n",
    "        ggplot(aes(xmin=start_datetime, xmax=end_datetime, ymin=rank-0.4, ymax=rank+0.4, fill=op)) +\n",
    "        geom_rect() + theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        ggtitle(\"I/O operations with duration longer than the median duration per operation\") +\n",
    "        my_theme() + scale_x_datetime(\"Execution time\", date_breaks = \"10 sec\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        scale_y_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,4)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p      \n",
    "\n",
    "    ggsave(filename=figname, plot = p, height=3, width=10)                                                                   \n",
    "}\n",
    "\n",
    "plot_max_temporal <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        mutate(start = timestamp - dur) %>%\n",
    "        mutate(end_datetime = as_datetime(timestamp),\n",
    "            start_datetime = as_datetime(start),) %>%\n",
    "        mutate(start_zero = start - min(start)) %>%\n",
    "        mutate(end_zero = start_zero + dur) %>%\n",
    "        filter(module == \"POSIX\")               \n",
    "\n",
    "    # Filter only operations that took longer than the median\n",
    "    df %>% group_by(op, rank) %>% \n",
    "        mutate(max_dur = max(dur)) %>%\n",
    "        filter(dur == max_dur) %>%\n",
    "        ungroup() %>%\n",
    "        ggplot(aes(xmin=start_datetime, xmax=end_datetime, ymin=rank-0.4, ymax=rank+0.4, fill=op)) +\n",
    "        geom_rect() + theme(panel.grid.major.x=element_blank(), axis.title.x=element_blank()) + \n",
    "        ggtitle(\"I/O operations with longer duration for each rank\") +\n",
    "        my_theme() + scale_x_datetime(\"Execution time\", date_breaks = \"10 sec\", expand=c(0,0), date_labels = \"%H:%M:%S\") +\n",
    "        scale_y_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,4)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p      \n",
    "\n",
    "    ggsave(filename=figname, plot = p, height=3, width=10)                                                                   \n",
    "}\n",
    "\n",
    "plot_duration <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>% \n",
    "        filter(op %in% c(\"write\", \"read\")) %>% \n",
    "        group_by(rank, op) %>% \n",
    "        summarise(mean_dur = mean(dur), median_dur = median(dur), sum_dur = sum(dur)) -> df.plot \n",
    "\n",
    "    df.plot %>%\n",
    "        ggplot(aes(x = rank, y=mean_dur, fill=op)) +\n",
    "        geom_bar(stat=\"identity\", position = \"dodge\", color=\"black\") + \n",
    "        my_theme() +\n",
    "        scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,1)) +\n",
    "        scale_y_continuous(\"Mean duration\\n(seconds)\", expand=c(0,0), lim=c(0, NA)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) -> p1      \n",
    "\n",
    "    df.plot %>%\n",
    "        ggplot(aes(x = rank, y=median_dur, fill=op)) +\n",
    "        geom_bar(stat=\"identity\", position = \"dodge\", color=\"black\") + \n",
    "        my_theme() +\n",
    "        scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,1)) +\n",
    "        scale_y_continuous(\"Median duration\\n(seconds)\", expand=c(0,0), lim=c(0, NA)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) + theme(legend.position=\"none\") -> p2\n",
    "\n",
    "    df.plot %>%\n",
    "        ggplot(aes(x = rank, y=sum_dur, fill=op)) +\n",
    "        geom_bar(stat=\"identity\", position = \"dodge\", color=\"black\") + \n",
    "        my_theme() +\n",
    "        scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,1)) +\n",
    "        scale_y_continuous(\"Sum duration\\n(seconds)\", expand=c(0,0), lim=c(0, NA), breaks=seq(0,10000,10)) +\n",
    "        guides(fill=guide_legend(title=\"Operation\")) + theme(legend.position=\"none\") -> p3\n",
    "\n",
    "    ggsave(filename=figname, plot = p1/p2/p3, height=6, width=10)                                                                   \n",
    "}\n",
    "\n",
    "plot_bandwidth_per_rank <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        filter(op == \"write\") %>% \n",
    "        group_by(op, rank) %>% \n",
    "        summarise(bw = sum(len)/(2^20)/sum(dur)) %>%\n",
    "        ggplot(aes(rank, op, fill= bw)) + \n",
    "        geom_tile() + scale_fill_viridis(discrete=FALSE, name=\"Bandwidth (MiB/seconds)\") +\n",
    "        scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,2)) +\n",
    "        my_theme() + theme(axis.title.y = element_blank()) -> p1    \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        filter(op == \"read\") %>% \n",
    "        group_by(op, rank) %>% \n",
    "        summarise(bw = sum(len)/(2^20)/sum(dur)) %>%\n",
    "        ggplot(aes(rank, op, fill= bw)) + \n",
    "        geom_tile() + scale_fill_viridis(discrete=FALSE, name=\"Bandwidth (MiB/seconds)\") +\n",
    "        scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,2)) +\n",
    "        my_theme() + theme(axis.title.y = element_blank()) -> p2\n",
    "\n",
    "    ggsave(filename=figname, plot = p1/p2, height=3.5, width=8)                                                                   \n",
    "}\n",
    "\n",
    "\n",
    "plot_heatmap_temporal <- function(filename, figname) { \n",
    "\n",
    "    df <- read_csv(filename) %>%\n",
    "        mutate(start = timestamp - dur) %>%\n",
    "        mutate(end_datetime = as_datetime(timestamp),\n",
    "            start_datetime = as_datetime(start),) %>%\n",
    "        mutate(start_zero = start - min(start)) %>%\n",
    "        mutate(end_zero = start_zero + dur) %>%\n",
    "        filter(module == \"POSIX\")               \n",
    "\n",
    "    df %>%\n",
    "        filter(op == \"read\") %>% \n",
    "        mutate(TIME_SLICE = round_time(start_datetime, unit = \"0.5 seconds\")) %>%\n",
    "        group_by(TIME_SLICE, rank) %>%\n",
    "        summarise(n=n(), bw = (sum(len)/(2^20))/sum(dur)) %>% print()\n",
    "\n",
    "    # df.slices %>%\n",
    "    #     ggplot(aes(rank, TIME_SLICE, fill= bw)) + \n",
    "    #     geom_tile() + scale_fill_viridis(discrete=FALSE, name=\"Bandwidth (MiB/seconds)\") +\n",
    "    #     scale_x_continuous(\"Rank ID\", expand=c(0,0), lim=c(-0.5, NA), breaks=seq(0,124,2)) +\n",
    "    #     my_theme() + theme(axis.title.y = element_blank()) -> p\n",
    "\n",
    "    # ggsave(filename=figname, plot = p, height=3, width=10)                                                               \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
